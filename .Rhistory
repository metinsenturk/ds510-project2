# model
svm_model <- svm(f_0, data = data_train,
kernel = "radial",
gamma = 0.005,
cost = 2,
decision.values=T,
scale = F,
type = "C-classification")
# roc
preds <- predict(svm_model, data_train, decision.values = T)
attrs <- attributes(preds)$decision.values
rocplot(attrs, data_train$AHD)
# svm model ====
# model
svm_model <- svm(f_0, data = data_train,
kernel = "radial",
gamma = 0.005,
cost = 2,
decision.values=T,
scale = F,
type = "C-classification")
summary(svm_model)
# svm model ====
# model
svm_model <- svm(f_0, data = data_train,
kernel = "radial",
gamma = 1,
cost = 1,
decision.values=T,
scale = F,
type = "C-classification")
summary(svm_model)
# plotting variables individually
plot(data_train$Age, y = data_train$AHD, col = 2)
par(new=T)
plot(data_train[,2], svm_model$fitted, col = 3)
# conf matrix
preds <- predict(svm_model, data_train)
confmatrix(preds, data_train$AHD)
# roc
preds <- predict(svm_model, data_train, decision.values = T)
attrs <- attributes(preds)$decision.values
rocplot(attrs, data_train$AHD)
2^(-1:1)
2^(1:10)
2^-10
2^-2
2^-4
2^-3
2^(-1:2)
2^(-1:3)
# tuning
svm_tune <- tune(svm, f_0, data = data_train,
kernel = "radial",
ranges = list(gamma = 2^(-1:3), cost = 2^(-3:10)))
summary(svm_tune)
svm_tune$best.parameters
# svm model ====
# model
svm_model <- svm(f_0, data = data_train,
kernel = "radial",
gamma = 0.5,
cost = 0.25,
decision.values=T,
scale = F,
type = "C-classification")
summary(svm_model)
# plotting variables individually
plot(data_train$Age, y = data_train$AHD, col = 2)
par(new=T)
plot(data_train[,2], svm_model$fitted, col = 3)
# conf matrix
preds <- predict(svm_model, data_train)
confmatrix(preds, data_train$AHD)
# roc
preds <- predict(svm_model, data_train, decision.values = T)
attrs <- attributes(preds)$decision.values
rocplot(attrs, data_train$AHD)
summary(svm_tune)
svm_tune$best.parameters
svm_tune$best.model
# tuning
svm_tune <- tune(svm, f_1, data = data_train,
kernel = "radial",
ranges = list(gamma = 2^(-1:3), cost = 2^(-3:10)))
f_1 <- AHD ~ MaxHR + Oldpeak + RestBP
# tuning
svm_tune <- tune(svm, f_1, data = data_train,
kernel = "radial",
ranges = list(gamma = 2^(-1:3), cost = 2^(-3:10)))
summary(svm_tune)
svm_tune$best.model
# svm model ====
# model
svm_model <- svm(f_1, data = data_train,
kernel = "radial",
gamma = 0.5,
cost = 0.25,
decision.values=T,
scale = F,
type = "C-classification")
summary(svm_model)
# svm model ====
# model
svm_model <- svm(f_1, data = data_train,
kernel = "radial",
gamma = 0.5,
cost = 0.5,
decision.values=T,
scale = F,
type = "C-classification")
summary(svm_model)
# plotting variables individually
plot(data_train$Age, y = data_train$AHD, col = 2)
par(new=T)
plot(data_train[,2], svm_model$fitted, col = 3)
# conf matrix
preds <- predict(svm_model, data_train)
confmatrix(preds, data_train$AHD)
# roc
preds <- predict(svm_model, data_train, decision.values = T)
attrs <- attributes(preds)$decision.values
rocplot(attrs, data_train$AHD)
# tuning
svm_tune <- tune(svm, f_1, data = data_train,
kernel = "radial",
ranges = list(gamma = 2^(-1:3), cost = 2^(-3:10)))
2^(-1:10)
2^(-1:3)
# tuning
svm_tune <- tune(svm, f_1, data = data_train,
kernel = "radial",
ranges = list(gamma = 2^(-1:2), cost = 2^(-1:10)))
summary(svm_tune)
svm_tune$best.model
# svm model ====
# model
svm_model <- svm(f_1, data = data_train,
kernel = "radial",
gamma = 1,
cost = 0.5,
decision.values=T,
scale = F,
type = "C-classification")
summary(svm_model)
# conf matrix
preds <- predict(svm_model, data_train)
confmatrix(preds, data_train$AHD)
svm_tune$best.performance
svm_tune$method
svm_tune$best.parameters
svm_tune$train.ind
svm_tune$best.model
# tuning
svm_tune <- tune(svm, f_1, data = data_train,
kernel = "radial",
type = "C-classification",
ranges = list(gamma = 2^(-1:2), cost = 2^(-1:10)))
summary(svm_tune)
svm_tune$method
svm_tune$best.model
svm_tune$best.parameters
svm_tune$best.performance
# conf matrix
preds <- predict(svm_model, data_train)
confmatrix(preds, data_train$AHD)
source("Scripts/model_functions.R")
confmatrix(preds, data_train$AHD)
summary(svm_tune)
head %>% summary(svm_tune)
head(summary(svm_tune))
head(summary(svm_tune))
summary(svm_tune)
svm_tune$method
svm_tune$performances
head(svm_tune$performances)
svm_model <- svm_tune$best.model
svm_tune$best.parameters
svm_tune$best.performance
head(svm_tune$performances)
svm_tune$best.parameters
svm_tune$best.parameters
head(svm_tune$performances)
svm_tune$best.performance
# tuning
svm_tune <- tune(svm, f_1, data = data_train,
kernel = "radial",
type = "C-classification",
decision.values=T,
scale = F,
ranges = list(gamma = 2^(-1:2), cost = 2^(-1:10)))
svm_tune$best.parameters
head(svm_tune$performances)
svm_model <- svm_tune$best.model
# plotting variables individually
plot(data_train$Age, y = data_train$AHD, col = 2)
par(new=T)
plot(data_train[,2], svm_model$fitted, col = 3)
# roc
preds <- predict(svm_model, data_train, decision.values = T)
attrs <- attributes(preds)$decision.values
rocplot(attrs, data_train$AHD)
# conf matrix
preds <- predict(svm_model, data_train)
confmatrix(preds, data_train$AHD)
set.seed()
# applying model to test data
# roc for test
preds <- predict(svm_model, data_test, decision.values = T)
attrs <- attributes(preds)$decision.values
rocplot(attrs, data_test$AHD)
# conf matrix
preds <- predict(svm_model, data_test)
confmatrix(preds, data_test$AHD)
str(knitr::knit_engines$get())
knitr::knit_engines$set(txt)
knitr::knit_engines$set("txt")
rocplot_compare(train_predictions, test_predictions, actual, ...){
# compares roc plot btw train and test datasets
# args:
#   preds: output of predict function
#   actual: predictor dataset
#   ... : graph paramaters
# returns:
#   two roc plots
# train
predt_tr = prediction(train_predictions, actual)
perf_tr = performance(predt_tr, "tpr", "fpr")
# train
predt_te = prediction(test_predictions, actual)
perf_te = performance(predt_te, "tpr", "fpr")
#plotting
par(mfrow = c(1,2))
plot(perf_tr, col=rainbow(7), main="ROC Curve for Train Data", ...)
abline(0, 1)
plot(perf_te, col=rainbow(7), main="ROC Curve Test Data", ...)
abline(0, 1)
par(mfrow = c(1,1))
}
knitr::opts_chunk$set(echo = T, tidy = T)
knitr::knit_engines$set("txt")
# plotting the model fit on the data
probs <- predict(lgm_model, data_train, type = "response")
logi.hist.plot(probs,
data_train$AHD,
boxp = F,
type = "count",
col = "gray",
xlabel = "")
install.packages("popbio")
library(popbio)
logi.hist.plot(probs,
data_train$AHD,
boxp = F,
type = "count",
col = "gray",
xlabel = "")
probs
data_train$AHD
warnings()
warnings()
#kfold
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F)
install.packages("caret")
install.packages("caret")
library(caret)
#kfold
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F)
training <- data_raw[ Train, ]
testing <- data_test[ -Train, ]
mod_fit <- train(f_0, data=training, method="glm", family="binomial")
exp(coef(mod_fit$finalModel))
predict(mod_fit, newdata=testing)
predict(mod_fit, newdata=testing, type="prob")
confmatrix(t, testing$AHD)
t < - predict(mod_fit, newdata=testing, type = "response")
t < - predict(mod_fit, newdata=testing, type = "response")
t < - predict(mod_fit, testing, type = "response")
t < - predict(mod_fit, testing)
t < - predict(mod_fit, newdata = testing)
mod_fit <- train(f_0, data=training, method="glm", family="binomial")
exp(coef(mod_fit$finalModel))
t < - predict(mod_fit, newdata = testing)
summary(mod_fit)
#kfold
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F)
training <- data_raw[ Train, c(2, 5, 6, 9, 11,15)]
testing <- data_test[ -Train, c(2, 5, 6, 9, 11,15) ]
mod_fit <- train(f_0, data=training, method="glm", family="binomial")
#kfold
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F)
training <- data_raw[ Train, c(2, 5, 6, 9, 11,15)]
testing <- data_raw[ -Train, c(2, 5, 6, 9, 11,15) ]
mod_fit <- train(f_0, data=training, method="glm", family="binomial")
summary(mod_fit)
exp(coef(mod_fit$finalModel))
t < - predict(mod_fit, newdata = testing)
predict(mod_fit, newdata=testing, type="prob")
mod_fit$results
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
#kfold
# https://www.r-bloggers.com/evaluating-logistic-regression-models/
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F, trControl = ctrl, tuneLength = 5)
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F, trControl = ctrl)
#kfold
# https://www.r-bloggers.com/evaluating-logistic-regression-models/
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F, trControl = ctrl, tuneLength = 5)
Train <- createDataPartition(data_raw$AHD, p=0.6, list=F)
#kfold
# https://www.r-bloggers.com/evaluating-logistic-regression-models/
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_fit <- train(f_0, data=data_raw[ , c(2, 5, 6, 9, 11,15)], method="glm", family="binomial", trControl = ctrl, tuneLength = 5)
summary(mod_fit)
summary(mod_fit)
exp(coef(mod_fit$finalModel))
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
plot(mod_fit)
mod_fit <- train(f_0, data=training, method="glm", family="binomial")
install.packages("caret")
install.packages("caret")
#kfold
# https://www.r-bloggers.com/evaluating-logistic-regression-models/
train_index <- createDataPartition(data_raw$AHD, p=0.8, list=F)
training <- data_raw[ train_index, c(2, 5, 6, 9, 11,15)]
library(caret)
#kfold
# https://www.r-bloggers.com/evaluating-logistic-regression-models/
train_index <- createDataPartition(data_raw$AHD, p=0.8, list=F)
training <- data_raw[ train_index, c(2, 5, 6, 9, 11,15)]
testing <- data_raw[ -train_index, c(2, 5, 6, 9, 11,15)]
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10,
savePredictions = TRUE)
mod_fit <- train(f_0, data=training,
method="glm", family="binomial",
trControl = ctrl)
summary(mod_fit)
exp(coef(mod_fit$finalModel))
summary(mod_fit$finalModel)
mod_fit$finalModel$converged
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
lgm_model <- mod_fit$finalModel
summary(mod_fit)
names(getModelInfo())
mod_fit <- train(f_0, data=training,
method="gbm", family="binomial",
trControl = ctrl)
mod_fit <- train(f_0, data=training,
method="glm", family="binomial",
trControl = ctrl)
summary(mod_fit)
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
lgm_model <- mod_fit$finalModel
summary(mod_fit$finalModel)
exp(coef(mod_fit$finalModel))
lgm_model = glm(f_0, data = data_train, family = binomial)
summary(lgm_model)
lgm_model <- mod_fit$finalModel
summary(mod_fit$finalModel)
exp(coef(mod_fit$finalModel))
pred <- predict(lgm_model, training, type = "response")
confmatrix(pred, training$AHD)
source("Scripts/model_functions.R")
confmatrix(pred, training$AHD)
summary(mod_fit$finalModel)
confusionMatrix(data = pred, testing$AHD)
confusionMatrix(data = pred, testing$AHD)
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
#kfold
# https://www.r-bloggers.com/evaluating-logistic-regression-models/
train_index <- createDataPartition(data_raw$AHD, p=0.8, list=F)
training <- data_raw[ train_index, c(2, 5, 6, 9, 11,15)]
testing <- data_raw[ -train_index, c(2, 5, 6, 9, 11,15)]
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10,
savePredictions = TRUE)
mod_fit <- train(f_0, data=training,
method="glm", family="binomial",
trControl = ctrl)
summary(mod_fit)
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
plot(mod_fit)
mod_fit <- train(f_0, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneGrid = grid,
tuneLength = 10)
plot(mod_fit)
grid <- expand.grid(C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2,5))
grid
grid <- expand.grid(C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 5))
mod_fit <- train(f_0, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneGrid = grid,
tuneLength = 10)
summary(mod_fit)
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
plot(mod_fit)
confusionMatrix(data = pred, testing$AHD)
mod_fit
summary(mod_fit)
mod_fit
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
plot(mod_fit)
mod_fit <- train(f_0, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
mod_fit
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
mod_fit <- train(f_1, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
mod_fit
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
plot(mod_fit)
mod_fit <- train(f_3, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
mod_fit
summary(mod_fit)
mod_fit <- train(f_1, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
summary(mod_fit)
mod_fit
mod_fit <- train(f_3, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
summary(mod_fit)
mod_fit
mod_fit <- train(f_0, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
summary(mod_fit)
mod_fit
summary(mod_fit)
mod_fit
mod_fit <- train(f_3, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
summary(mod_fit)
mod_fit
pred <- predict(mod_fit, newdata=testing)
confusionMatrix(data = pred, testing$AHD)
pred <- predict(mod_fit, newdata=training)
confusionMatrix(data = pred, training$AHD)
plot(mod_fit)
train_index <- createDataPartition(data_raw$AHD, p=0.8, list=F)
training <- data_raw[ train_index, c(2, 5, 6, 9, 11,15)]
testing <- data_raw[ -train_index, c(2, 5, 6, 9, 11,15)]
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10,
savePredictions = TRUE)
time.start <- Sys.time()
mod_fit <- train(f_3, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
time.end <- Sys.time()
time.end - time.start
time.start <- Sys.time()
mod_fit <- train(f_3, data=training,
method="glm", family="binomial",
trControl = ctrl,
tuneLength = 10)
time.end <- Sys.time()
round(time.end - time.start, 2)
varimax(mod_fit)
varimax(lgm_model)
lgm_model = glm(f_0, data = data_train, family = binomial)
varimax(lgm_model)
varImp(lgm_model)
lgm_model = glm(f_3, data = data_train, family = binomial)
varImp(lgm_model)
lgm_model = glm(f_1, data = data_train, family = binomial)
varImp(lgm_model)
# variance importance of variables
varImp(lgm_model)
lgm_model = glm(f_0, data = data_train, family = binomial)
lgm_model_1 = glm(f_1, data = data_train, family = binomial)
lgm_model_2 = glm(f_2, data = data_train, family = binomial)
# Anova
anova(lgm_model_1, lgm_model_2)
# Anova
anova(lgm_model)
anova(lgm_model_1, lgm_model_2, test ="Chisq")
# variance importance of variables
varImp(lgm_model)
# Anova
anova(lgm_model)
mod_fit
summary(mod_fit)
